{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e24210",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545966e",
   "metadata": {},
   "source": [
    "We want to do a book recommendation system based on the data we have cleaned before.\n",
    "They are two types of recommender system:\n",
    "* Collaborative filtering:This system matches persons with similar interests and provides recommendations based on this matching. It needs the historical activity of the users which we have.In the case of algorithm using similarity like KNN, it can be user-based or item-based. In the first, we recommend items to a user that similar users have also liked. In the second, we recommend items based on the past ratings of similiar items by the user.\n",
    "\n",
    "* Content base systems: They suggest similar items based on a particular item. This system uses item metadata. The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it. \n",
    "\n",
    "The only metadata we have about the books in our dataset is the title, author and country wich is very little. A good metadata is the genres or the summary that sadly we haven't. This method is also computationally expensive. For this reasons, we only do collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a94ed",
   "metadata": {},
   "source": [
    "We want to predict the rating given by a user to a book based on the book that he has already read and the books of user that have like the same books i.e similar users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8f753",
   "metadata": {},
   "source": [
    "# Loading the data previously cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdbc6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2dded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:/Workspace_Python/MLProject/MachineLearningDSTIProject/dataset/\"\n",
    "file=\"final_dataset.csv\"\n",
    "users_csv=\"cleaned_users.csv\"\n",
    "books_csv=\"cleaned_books.csv\"\n",
    "ratings_csv=\"cleaned_ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9db7fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248251"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv(path+books_csv, sep=\";\",on_bad_lines='warn', encoding=\"latin-1\")\n",
    "books.bookId.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56beb2d9",
   "metadata": {},
   "source": [
    "## Choice of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb810d0",
   "metadata": {},
   "source": [
    "We use the library surprise to do the recommender system. It's a library specialised in this kind of machine learning. Sadly we could not use the age nor the location with this library as only 4 columns are allowed: user, item, rating and timestamp. The age and location could have been usefull to better determine the similitude between two users or items in the case of algorithm using similitude like KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b2563",
   "metadata": {},
   "source": [
    "We load the data into the data structure of the surprise library. For memory concern, we reduce the data to user having rated more than 5 books and book that have been rated more than 30 times to avoid memory arror."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d1d2133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads Pandas dataframe\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "#we reduce the size of the dataset by removing the user that rated less than 10 books and books \n",
    "#that have been rated less than 100 times\n",
    "df = pd.read_csv(path+file, sep=\";\",on_bad_lines='warn', encoding=\"latin-1\")\n",
    "df=df[df.userID.isin(df.userID.value_counts()[df.userID.value_counts()>5].index)][['userID','bookId','bookRating']]\n",
    "df=df[df.bookId.isin(df.bookId.value_counts()[df.bookId.value_counts()>30].index)][['userID','bookId','bookRating']]\n",
    "data = Dataset.load_from_df(df[['userID','bookId','bookRating']], Reader(line_format='user item rating', sep=\";\",rating_scale=(1, 10)))\n",
    "len(df.bookId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50d8afab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>102</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>103</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>119</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating timestamp\n",
       "0       99       97     8.0      None\n",
       "1       99      102    10.0      None\n",
       "2       99      103     3.0      None\n",
       "3      114      119    10.0      None\n",
       "4      114      115     9.0      None"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##to see what is in the built in data of surprise\n",
    "d=pd.DataFrame(data.__dict__['raw_ratings'], columns=['user_id','item_id','rating','timestamp'])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bfdcd1",
   "metadata": {},
   "source": [
    "We benchmark the different models by using a cross validation after having set the the seed of the RNG to have reproducible experiments. We use RMSE to measure the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bff64d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "my_seed = 42\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9be2acac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.592888</td>\n",
       "      <td>0.606324</td>\n",
       "      <td>0.079378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.594112</td>\n",
       "      <td>0.126038</td>\n",
       "      <td>0.050495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.604308</td>\n",
       "      <td>1.467182</td>\n",
       "      <td>0.344806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.688640</td>\n",
       "      <td>1.562571</td>\n",
       "      <td>0.985085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.709618</td>\n",
       "      <td>1.956382</td>\n",
       "      <td>0.051138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.755192</td>\n",
       "      <td>1.781914</td>\n",
       "      <td>1.018289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.760181</td>\n",
       "      <td>1.809061</td>\n",
       "      <td>0.929122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.778996</td>\n",
       "      <td>1.402033</td>\n",
       "      <td>0.886582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.862809</td>\n",
       "      <td>0.157636</td>\n",
       "      <td>0.173056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               test_rmse  fit_time  test_time\n",
       "Algorithm                                    \n",
       "SVD             1.592888  0.606324   0.079378\n",
       "BaselineOnly    1.594112  0.126038   0.050495\n",
       "SVDpp           1.604308  1.467182   0.344806\n",
       "KNNBaseline     1.688640  1.562571   0.985085\n",
       "CoClustering    1.709618  1.956382   0.051138\n",
       "KNNWithMeans    1.755192  1.781914   1.018289\n",
       "KNNWithZScore   1.760181  1.809061   0.929122\n",
       "KNNBasic        1.778996  1.402033   0.886582\n",
       "SlopeOne        1.862809  0.157636   0.173056"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import SlopeOne\n",
    "from surprise import KNNBaseline\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import BaselineOnly\n",
    "from surprise import CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(verbose =False), SVDpp(verbose =False), SlopeOne(), KNNBaseline(verbose =False), KNNBasic(verbose =False), KNNWithMeans(verbose =False), KNNWithZScore(verbose =False), BaselineOnly(verbose =False), CoClustering(verbose =False)]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = pd.concat([tmp,pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm'])])\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34537c50",
   "metadata": {},
   "source": [
    "BaselineOnly and SVD give us the best although BaselineOnly also give us the best time, so it' is one of this two we should use. As KNNBseline can be configured by using similitude we also futher test it with both user_based and item_based configuration.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee501b",
   "metadata": {},
   "source": [
    "## Hyper_tuning of BaseLineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2affe701",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5611580885598726\n",
      "{'bsl_options': {'method': 'als', 'n_epochs': 25, 'reg_u': 4, 'reg_i': 10}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "bsl_options = {\"method\": [\"als\"], \"n_epochs\": [10,15,20,25 ], \"reg_u\": [4,5,10,15,20], \"reg_i\": [5,10,15,20]}\n",
    "param_grid={\"bsl_options\":bsl_options}\n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=[\"rmse\", \"mae\"], cv=5,n_jobs =2, joblib_verbose=0)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "best_param_bsl=gs.best_params[\"rmse\"]\n",
    "print(best_param_bsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9879a0",
   "metadata": {},
   "source": [
    "## Hyper tuning of SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c06818c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5704311138983131\n",
      "{'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_epochs\": [15,20,25,30],\"lr_all\": [0.004,0.008,0.01,0.02],\"reg_all\": [0,0.02,0.4,0.5, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=5,n_jobs =2, joblib_verbose=0)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "best_param_svd=gs.best_params[\"rmse\"]\n",
    "print(best_param_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b31271",
   "metadata": {},
   "source": [
    "## Hyper tuning of KNNBaseLine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b67d8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"bsl_options = {\"method\": [\"als\"], \"n_epochs\": [15,20,25 ], \"reg_u\": [2,5,8,10], \"reg_i\": [2,4,6]}\\nsim_options = {\"name\": [\"cosine\"],\"user_based\": [True,False]}\\nparam_grid = {\"bsl_options\":bsl_options, \"sim_options\":sim_options, \"k\":[20,40,60]}\\ngs = GridSearchCV(KNNBaseline, param_grid, measures=[\"rmse\", \"mae\"], cv=5,n_jobs =2, joblib_verbose=0)\\ngs.fit(data)\\n\\nprint(gs.best_score[\"rmse\"])\\nprint(gs.best_params[\"rmse\"])'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"bsl_options = {\"method\": [\"als\"], \"n_epochs\": [15,20,25 ], \"reg_u\": [2,5,8,10], \"reg_i\": [2,4,6]}\n",
    "sim_options = {\"name\": [\"cosine\"],\"user_based\": [True,False]}\n",
    "param_grid = {\"bsl_options\":bsl_options, \"sim_options\":sim_options, \"k\":[20,40,60]}\n",
    "gs = GridSearchCV(KNNBaseline, param_grid, measures=[\"rmse\", \"mae\"], cv=5,n_jobs =2, joblib_verbose=0)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdea681",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f6074",
   "metadata": {},
   "source": [
    "The benchmark and the tunning of the model show that the best model is the BaseLineOnly with the Alternating Least Squares procedure configured with 25 iterations,reg_u=4 and reg_i=10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79da9099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x211e6347640>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "bsl_options= {'method': 'als', 'n_epochs': 25, 'reg_u': 4, 'reg_i': 10}\n",
    "trainset_bsl, testset_bsl = train_test_split(data, test_size=0.25)\n",
    "#trainset_bsl = data.build_full_trainset()\n",
    "algo_bsl = BaselineOnly(bsl_options=bsl_options,verbose =False)\n",
    "algo_bsl.fit(trainset_bsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e3e53ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x21303a9ef80>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_svd, testset_svd = train_test_split(data, test_size=0.25)\n",
    "#trainset_svd = data.build_full_trainset()\n",
    "algo_svd=SVD(n_epochs= 30, lr_all= 0.01, reg_all= 0.4)\n",
    "algo_svd.fit(trainset_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74296f3",
   "metadata": {},
   "source": [
    "To get the 5 best recommendation ofr each user we could use the method get_top_n provided by surprise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9742af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea94c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_by_algo(algo,trainset,k):\n",
    "    testset = trainset.build_anti_testset()\n",
    "    predictions = algo.test(testset)\n",
    "    return predictions,get_top_n(predictions, n=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ab1493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bsl,top_n_bsl = get_top_n_by_algo(algo_bsl,trainset_bsl,5)\n",
    "prediction_svd,top_n_svd = get_top_n_by_algo(algo_svd,trainset_svd,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e46632ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [\u001b[38;5;28mprint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtop_n\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_n' is not defined"
     ]
    }
   ],
   "source": [
    "[print(i) for i in top_n.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occ(reco,i):\n",
    "    if i in reco:reco[i]=reco.get(i)+1\n",
    "    else: reco[i]=1\n",
    "\n",
    "def count_books_recommended(rcd):\n",
    "    reco={}\n",
    "    [ [count_occ(reco,title[0]) for title in v]  for k,v in rcd.items()]\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_books_bsl=count_books_recommended(top_n_bsl)\n",
    "recommended_books_svd=count_books_recommended(top_n_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a381ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_book_by_id=lambda id_b:books.loc[books.bookId==id_b][\"bookTitle\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe354ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_by_id(id_u,top_n):\n",
    "    print(\"The recommendation for user\",id_u, \"are:\\n\")\n",
    "    [print(get_book_by_id(iid),\"with a rating of\",r,\"\\n\") for (iid, r) in top_n[id_u]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_book_recommended(recommended_books):\n",
    "    print(\" book title |\",\"nb recommended\")\n",
    "    [ print(get_book_by_id(k),v) for k,v in recommended_books.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b48e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The baseline model has recommended a total of\",len(recommended_books_bsl), \"distinct books\")\n",
    "print(\"The SVD model has recommended a total of\",len(recommended_books_svd), \"distinct books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecdbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"books recommended with baseline\")\n",
    "get_list_book_recommended(recommended_books_bsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d50c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"books recommended with svd\")\n",
    "get_list_book_recommended(recommended_books_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba76169",
   "metadata": {},
   "source": [
    "Example of recommendation for the user 229331:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646e79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_recommendation_by_id(229331,top_n_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125b888",
   "metadata": {},
   "source": [
    "We observe that on all the 806 books the svd model has recommended 43 books, 20 more that the baseline model so it has more versality than the baseline model. Nonetheless, this show one weakness in this kind of algorithm: it's always a minority of books that are recommended and books with few ratings can't be recommended hence all users are given more or less the same books. The only downside of SVD is its computing time that is longer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df53f9e8",
   "metadata": {},
   "source": [
    "Finally, we measure the accuracy of the ratings we have get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(predict):\n",
    "    accuracy.rmse(predict)\n",
    "    accuracy.mse(predict)\n",
    "    accuracy.mae(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7885730",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"metrics for baseline\")\n",
    "get_metrics(prediction_bsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e485c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"metrics for SVD\")\n",
    "get_metrics(prediction_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2b746",
   "metadata": {},
   "source": [
    "As a good recommender system should have RMSE under 1, we could say that this two model of recommender system are good. The SVD is a little bit more efficient but it is also more interesting because more different books are recommended. So this this algorithm that we choose to use.\n",
    "We can also compute the recall and precision at k which is a specific metrics for recommender system. The FAQ of the surprise library give this implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "def precision_recall_at_k(predictions, k=5, threshold=7):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a404d",
   "metadata": {},
   "source": [
    "We are now choosing wich book ratings we should recommend and how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a63766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_precision_F1(algo,k,t):\n",
    "    kf = KFold(n_splits=k)\n",
    "    mean_prec=0.\n",
    "    mean_recall=0.\n",
    "    i=0\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=t)\n",
    "        # Precision and recall can then be averaged over all users\n",
    "        p=sum(prec for prec in precisions.values()) / len(precisions)\n",
    "        r=sum(rec for rec in recalls.values()) / len(recalls)\n",
    "        mean_prec+=p\n",
    "        mean_recall+=r\n",
    "        i+=1\n",
    "    mean_prec, mean_recall=mean_prec/k,mean_recall/k\n",
    "    return mean_prec, mean_recall,2*mean_recall*mean_prec/(mean_recall+mean_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58365e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_data_k(algo,t):\n",
    "    k_array,prec_array,recall_array,f1_array=[],[],[],[]\n",
    "    for i in np.arange(2,16):\n",
    "        k_array.append(i)\n",
    "        result=get_recall_precision_F1(algo,i,t)\n",
    "        prec_array.append(result[0])\n",
    "        recall_array.append(result[1])\n",
    "        f1_array.append(result[2])\n",
    "    return k_array,prec_array,recall_array,f1_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_array,prec_array,recall_array,f1_array=get_f1_data_k(algo_svd,7)\n",
    "plt.plot(k_array,f1_array)\n",
    "plt.ylabel(\"F1_score\")\n",
    "plt.xlabel(\"Number of recommendation\")\n",
    "plt.title(\"F1_score of the SVD algorithm by Number of recommendation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f8dd6",
   "metadata": {},
   "source": [
    "We observe that the F1_score is maximal with 7 books recommended and that it doesn' have a great variation as it's approximatively always 80% after 5 books recommended, so this parameter is not very important in our case. 7 is still a good value as we don't want to recommend too many books as a user usually consider only the first books recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_data_t(algo,k):\n",
    "    r_array,prec_array,recall_array,f1_array=[],[],[],[]\n",
    "    for r in np.arange(2,11):\n",
    "        r_array.append(r)\n",
    "        result=get_recall_precision_F1(algo,k,r)\n",
    "        prec_array.append(result[0])\n",
    "        recall_array.append(result[1])\n",
    "        f1_array.append(result[2])\n",
    "    return r_array,prec_array,recall_array,f1_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "r_array,prec_array,recall_array,f1_array=get_f1_data_t(algo_svd,7)\n",
    "get_f1_data_t\n",
    "plt.plot(r_array,f1_array)\n",
    "plt.ylabel(\"F1_score\")\n",
    "plt.xlabel(\"Rating threshold\")\n",
    "plt.title(\"F1_score of the SVD algorithm by rating threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b831c9",
   "metadata": {},
   "source": [
    "We observe that the F1 score decrease with the increse of rating threshold wich is logical as more we are strict with the rating of the book to recommend more it'is difficult to respect the condition. The curve drop significantly after a threshold of 7. As book ratings of 5 and 6 are a little low to be recommended, We should use 7 as threshold even if a F1_score of 80% is a little low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbd1f1",
   "metadata": {},
   "source": [
    "We get a precision of 80%, a recall of 82% and a F1 score of 80% which is average and coherent with the results obtained with the RMSE. This model is acceptable for our need but a better model can/should be found and it will be inacceptable in many field such as health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea99b5",
   "metadata": {},
   "source": [
    "This machine learning problem has shown us two limits of recommender system only done with python: limitation of memory and time of computation. \n",
    "It partly explain why the graph database are so often used in the domain of recommendation. With this kind of base it's much more easy to find similar item or user as the algorithm just need to go from node to node based on relationship and we don't store useless informationin the memory, only usefull one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394bb90",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "\"Hands on recommendation systems with Python\" by Rounak Banik \n",
    "\n",
    "\"Graph-Powered Machine Learning\" by Alessandro Negro\n",
    "\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/FAQ.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlProject",
   "language": "python",
   "name": "mlproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
