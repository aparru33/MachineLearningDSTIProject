{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c545966e",
   "metadata": {},
   "source": [
    "We want to do a book recommendation system based on the data we have cleaned before.\n",
    "They are three types of recommender system:\n",
    "* Collaborative filtering:This system matches persons with similar interests and provides recommendations based on this matching. It needs the historical activity of the users which we have.It can be user-based or item-based. In the first, we recommend items to a user that similar users have also liked. In the second, we recommend items based on the past ratings of similiar items by the user.\n",
    "\n",
    "* Content base systems: They suggest similar items based on a particular item. This system uses item metadata. The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it. The only metadata we have about the books in our dataset is the title, author and country wich is very little. A good metadata is the genres or the summary that sadly we haven't. This method is also computationally expensive which is another reason we are not doing it.\n",
    "\n",
    "This system recommendation were mainly done with the helf of the book \"Hands on recommendation systems with Python\" by Rounak Banik \n",
    "https://learning.oreilly.com/library/view/hands-on-recommendation-systems/9781788993753/5f1269b2-2007-42a8-a900-bf255b86e64c.xhtml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a94ed",
   "metadata": {},
   "source": [
    "We want to predict the rating given by a user to a book based on the book that he has already read and the books of user that have like the same books i.e similar users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8f753",
   "metadata": {},
   "source": [
    "# Loading the data previously cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdbc6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a2dded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:/Workspace_Python/MLProject/MachineLearningDSTIProject/dataset/\"\n",
    "file=\"final_dataset.csv\"\n",
    "users_csv=\"cleaned_users.csv\"\n",
    "books_csv=\"cleaned_books.csv\"\n",
    "ratings_csv=\"cleaned_ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fca42950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+file, sep=\";\",on_bad_lines='warn', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ecc87",
   "metadata": {},
   "source": [
    "## Predict the age target of a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56fec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9290332",
   "metadata": {},
   "source": [
    "# Recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4702d3",
   "metadata": {},
   "source": [
    "## Item-based ou user-based collaborative filtering ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f8f446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278858, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(path+users_csv, sep=\";\",on_bad_lines='warn', encoding=\"latin-1\")\n",
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9db7fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271379, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv(path+books_csv, sep=\";\",on_bad_lines='warn', encoding=\"latin-1\")\n",
    "books.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96a7a9",
   "metadata": {},
   "source": [
    "As we have approximatively as much users than books and we have huge disparity in the number of ratings between users as seen in the EDA, we choose to use the item-based collaborative filtering wich should also be more efficient\n",
    "\n",
    "to review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56beb2d9",
   "metadata": {},
   "source": [
    "## Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43600547",
   "metadata": {},
   "source": [
    "We use the library surprise to do the recommender system. It's a library specialised in this kind of machine learning. Sadly we could not use the age with this library as only 4 columns are allowed: user, item, rating and timestamp. The age could have bee, useful to better determine the similitude between two users or item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b2563",
   "metadata": {},
   "source": [
    "We load the data into the data structure of the surprise library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb8f6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads Pandas dataframe\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "#we reduce the size of the dataset by removing the user that rated less than 10 books and books \n",
    "#that have been rated less than 100 times\n",
    "df=df[df.userID.isin(df.userID.value_counts()[df.userID.value_counts()>10].index)][['userID','bookId','bookRating']]\n",
    "df=df[df.bookId.isin(df.bookId.value_counts()[df.bookId.value_counts()>100].index)][['userID','bookId','bookRating']]\n",
    "data = Dataset.load_from_df(df[['userID','bookId','bookRating']], Reader(line_format='user item rating', sep=\";\",rating_scale=(1, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50d8afab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>180</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243</td>\n",
       "      <td>306</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>243</td>\n",
       "      <td>834</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>4825</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>3460</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating timestamp\n",
       "0      242      180     8.0      None\n",
       "1      243      306     7.0      None\n",
       "2      243      834     9.0      None\n",
       "3      243     4825     9.0      None\n",
       "4      254     3460     9.0      None"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##to see what is in the built in data of surprise\n",
    "d=pd.DataFrame(data.__dict__['raw_ratings'], columns=['user_id','item_id','rating','timestamp'])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bfdcd1",
   "metadata": {},
   "source": [
    "We benchmark the different models by using a cross validation after having set the the seed of the RNG to have reproducible experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bff64d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9be2acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrie\\AppData\\Local\\Temp\\ipykernel_21080\\1018682062.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.625641</td>\n",
       "      <td>0.092082</td>\n",
       "      <td>0.010992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.628368</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.662919</td>\n",
       "      <td>0.183550</td>\n",
       "      <td>0.187955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.680837</td>\n",
       "      <td>0.095030</td>\n",
       "      <td>0.029158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.738697</td>\n",
       "      <td>0.169970</td>\n",
       "      <td>0.157416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.844757</td>\n",
       "      <td>0.411104</td>\n",
       "      <td>0.007960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.853848</td>\n",
       "      <td>0.213422</td>\n",
       "      <td>0.164554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.869185</td>\n",
       "      <td>0.040720</td>\n",
       "      <td>0.013561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.890926</td>\n",
       "      <td>0.342794</td>\n",
       "      <td>0.178875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>2.479706</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.008215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>2.759598</td>\n",
       "      <td>0.257447</td>\n",
       "      <td>0.010663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "SVD               1.625641  0.092082   0.010992\n",
       "BaselineOnly      1.628368  0.012713   0.007202\n",
       "KNNBaseline       1.662919  0.183550   0.187955\n",
       "SVDpp             1.680837  0.095030   0.029158\n",
       "KNNBasic          1.738697  0.169970   0.157416\n",
       "CoClustering      1.844757  0.411104   0.007960\n",
       "KNNWithMeans      1.853848  0.213422   0.164554\n",
       "SlopeOne          1.869185  0.040720   0.013561\n",
       "KNNWithZScore     1.890926  0.342794   0.178875\n",
       "NormalPredictor   2.479706  0.007007   0.008215\n",
       "NMF               2.759598  0.257447   0.010663"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import SlopeOne\n",
    "from surprise import NMF\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBaseline\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import BaselineOnly\n",
    "from surprise import CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34537c50",
   "metadata": {},
   "source": [
    "BaselineOnly and SVD give us the best although BaselineOnly also give us the best time, so it' is this one we should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af8002cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ALS\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.62038706, 1.59679814, 1.59217462, 1.6297444 , 1.66474006]),\n",
       " 'fit_time': (0.009596109390258789,\n",
       "  0.008472919464111328,\n",
       "  0.007867813110351562,\n",
       "  0.007852554321289062,\n",
       "  0.006787300109863281),\n",
       " 'test_time': (0.007916450500488281,\n",
       "  0.0073468685150146484,\n",
       "  0.007341146469116211,\n",
       "  0.006822347640991211,\n",
       "  0.007322072982788086)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Using ALS')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79da9099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "predictions = algo.fit(trainset).test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df53f9e8",
   "metadata": {},
   "source": [
    "Finally, we measure the accuracy of the ratings we have calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7885730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.6762\n",
      "MSE: 2.8096\n",
      "MAE:  1.2918\n",
      "FCP:  0.5344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5344255900136532"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "accuracy.fcp(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36355503",
   "metadata": {},
   "source": [
    "We tune the algorithm parameters by using grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "to_do\n",
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True],\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669c4f8",
   "metadata": {},
   "source": [
    "We can now do some prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b199e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3a1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from neo4j import GraphDatabase\n",
    "#driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"DSTI2023!!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlProject",
   "language": "python",
   "name": "mlproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
